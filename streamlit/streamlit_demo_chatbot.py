from langchain_community.vectorstores.faiss import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain.tools import tool
from langchain.agents import initialize_agent, AgentType
from langchain_openai import ChatOpenAI
from langchain_community.utilities.sql_database import SQLDatabase
from langchain_core.messages import HumanMessage,AIMessage
from langchain.chains.llm import LLMChain
import csv,sqlite3,ast,re,json
import os,sys,time
from pydantic import BaseModel
import streamlit as st 
from langchain_core.prompts import (
    ChatPromptTemplate,
    FewShotPromptTemplate,
    MessagesPlaceholder,
    PromptTemplate,
    SystemMessagePromptTemplate,
)
# Get the absolute path of the project directory
project_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
# Add the project directory to sys.path
sys.path.append(project_path)
from source.sql_qa.sql_creator import SQLCreatorServer
from source.sql_qa.agent_creator import AgentCreatorSQL
from source.rag_qa.rag_creator import RetrieverCreator
from source.history.process_history import HistoryProcessor
# from langchain.pydantic_v1 import BaseModel, Field
# class HumanInput(BaseModel):
#     question_human: str = Field(description="L√† c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng, kh√¥ng ch·ªânh s·ª≠a c·∫Øt b·ªè hay th√™m b·ªõt g√¨")
# # os.environ["OPENAI_API_KEY"] = ""
os.environ["OPENAI_API_KEY"] = ""
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
# create model embedding in openAi
model_embed = OpenAIEmbeddings(model="text-embedding-3-large")
#T·∫°o database retriever
db_retriever=FAISS.load_local("D:/Chatbot_langchains_openAI/vectorstore/store_204_items",model_embed,allow_dangerous_deserialization=True)
db_sql = SQLDatabase.from_uri("sqlite:///D:/Chatbot_langchains_openAI/streamlit/database_204_items.db")
# status= False #"L·∫ßn ƒë·∫ßu" = True 
# if status:
#     SQLCreatorServer().create_table_SQLite(csv_file_path_local="D:/Chatbot_langchains_openAI/data/data_csv/204_final_edited.csv",
#                                        name_table="data_items")
sql_agent=AgentCreatorSQL().create_SQL_agent(llm,model_embed,db_sql)
agent_retriever=RetrieverCreator().create_retriever_chain(llm,db_retriever)
def answer(id_user,id_conversation,question):
    chat_history=HistoryProcessor().load_history(id_user,id_conversation)
    format_chat_his=[]
    for tmp_his in chat_history[-3:]:
        format_chat_his.append(HumanMessage(content=tmp_his["HumanMessage"]))
        format_chat_his.append(AIMessage(content=tmp_his["AIMessage"]))
    examples = [
        {"input": "Nh√† c·ªßa t√¥i ƒëang kh√¥ng c√≥ d·ª•ng c·ª• n·∫•u ƒÉn", "tool_selected": "retriever"},
        {"input": "C√≥ t·∫•t c·∫£ bao nhi√™u s·∫£n ph·∫©m m√°y gi·∫∑t", "tool_selected": "sql"},
        {"input": "T√¥i c·∫ßn m·ªôt s·ªë g·ª£i √Ω v·ªÅ s·∫£n ph·∫©m h·ªó tr·ª£ chi·∫øu s√°ng trong nh√†", "tool_selected": "retriever"},
        {"input": "So s√°nh gi√° c√°c s·∫£n ph·∫©m ƒë√®n nƒÉng l∆∞·ª£ng m·∫∑t tr·ªùi gi√∫p t√¥i ƒë∆∞·ª£c kh√¥ng?", "tool_selected": "sql"},
    ]
    # M·∫´u prompt
    example_template = "Input: {input}\ntool_selected: {tool_selected}"
    # T·∫°o PromptTemplate cho c√°c v√≠ d·ª•
    example_prompt = PromptTemplate(
        input_variables=["input", "tool_selected"],
        template=example_template
    )
    # T·∫°o FewShotPromptTemplate
    system_prefix="""B·∫°n l√† m·ªôt tr·ª£ l√Ω h·ªó tr·ª£ nh·∫≠n bi·∫øt tool ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi. Ch·ªâ tr·∫£ ra "retriever" ho·∫∑c "sql", kh√¥ng c√≥ tool n√†o kh√°c.
    T√¥i c√≥ 2 tool h·ªó tr·ª£ tr·∫£ l·ªùi c√¢u h·ªèi l√† "retriever" v√† "sql".
    Tool retriever s·ª≠ d·ª•ng khi c√¢u h·ªèi c√≥ √Ω ƒë·ªãnh l√† 1 s·ªë lo·∫°i sau: ch√†o h·ªèi giao ti·∫øp x√£ giao b√¨nh th∆∞·ªùng, mu·ªën t∆∞ v·∫•n nh∆∞ng kh√¥ng n√≥i c·ª• th·ªÉ v·ªÅ s·∫£n ph·∫©m l√† g√¨.KH√îNG d√πng tool n√†y ƒë·ªÉ tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ s·ªë l∆∞·ª£ng.KH√îNG d√πng tool n√†y ƒë·ªÉ tr·∫£ l·ªùi c√°c c√¢u h·ªèi so s√°nh tr√™n 2 s·∫£n ph·∫©m kh√°c nhau.Kh√¥ng d√πng tool n√†y khi m·ª•c ƒë√≠ch l√† t√≠nh to√°n ti·ªÅn s·∫£n ph·∫©m.
    Tool sql s·ª≠ d·ª•ng khi c√¢u h·ªèi c√≥ √Ω ƒë·ªãnh l√† 1 s·ªë lo·∫°i sau: c√≥ ƒë·ªÅ c·∫≠p ƒë·∫øn h·ªèi s·ªë l∆∞·ª£ng, c√≥ ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác so s√°nh g√¨ ƒë√≥, c√≥ ƒë·ªÅ c·∫≠p v·∫•n ƒë·ªÅ t√≠nh to√°n ti·ªÅn s·∫£n ph·∫©m
    D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë v√≠ d·ª• v·ªÅ ph√¢n lo·∫°i tool s·ª≠ d·ª•ng ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi. D·ª±a tr√™n c√°c v√≠ d·ª• n√†y, ph√¢n lo·∫°i tool cho vƒÉn b·∫£n c√¢u h·ªèi m·ªõi.
    """
    prompt_template = FewShotPromptTemplate(
        examples=examples,
        example_prompt=example_prompt,
        prefix=system_prefix,
        suffix="Input: {question}\ntool_selected:",
        input_variables=["question"]
    )
    # T·∫°o LLMChain v·ªõi prompt template
    tool_classification_chain = LLMChain(llm=llm, prompt=prompt_template)
    # print("chat_history: ",chat_history)
    tool_selected=tool_classification_chain.run({"question": question})
    print("tool_selected: ",tool_selected)
    if tool_selected.find("sql") != -1 :
        response=sql_agent.invoke({"input":question,
                                   #  'top_k': 3,
                                 "history":format_chat_his})
        # print(response)
        print("C√¢u h·ªèi: ",response['input'])
        print("L·ªãch s·ª≠ h·ªôi tho·∫°i: ",response['history'])
        print("Tr·∫£ l·ªùi: ",response['output'])
        result=response['output']
    else:
        response=agent_retriever.invoke({"input":question,
                                        "chat_history":format_chat_his})
        # print(response)
        print("C√¢u h·ªèi: ",response['input'])
        print("L·ªãch s·ª≠ h·ªôi tho·∫°i: ",response['chat_history'])
        print("Context ƒë·∫ßu v√†o LLM: ", response['context'])
        print("Tr·∫£ l·ªùi: ",response['answer'])
        result=response["answer"]
    HistoryProcessor().update_history(id_user,id_conversation,HumanMessage=question,AIMessage=result)
    return result

# streamlit ##################################################
original_title = '<h1 style="font-family: serif; color:white; font-size: 20px;">‚ú®Langchain ü¶úüîó </h1>'
st.markdown(original_title, unsafe_allow_html=True)
# Set the background image
background_image = """
<style>
[data-testid="stAppViewContainer"] > .main {
    background-image: url("https://hoanghamobile.com/tin-tuc/wp-content/webp-express/webp-images/uploads/2023/07/hinh-dep-2.jpg.webp");
    background-size: 100vw 100vh;  # This sets the size to cover 100% of the viewport width and height
    background-position: center;  
    background-repeat: no-repeat;
}
</style>
"""
st.markdown(background_image, unsafe_allow_html=True)
st.markdown(
    """
    <style>
    .reportview-container .main .block-container div[data-baseweb="toast"] {
        background-color: red;
    }
    </style>
    """,
    unsafe_allow_html=True,
)
st.title('ü¶úüîó CHATBOT')
with st.form('my_form'):
    # User inputs
    user_id = st.text_input('Nh·∫≠p ID c·ªßa b·∫°n:')
    id_conversation = st.text_input('Nh·∫≠p id h·ªôi tho·∫°i:')
    text = st.text_area('Anh Huy h·ªèi em ƒëiiii:')
    # print("id_conversation: ", id_conversation)
    # print("user_id: ", user_id)
    # print("text: ", text)
    submitted = st.form_submit_button('·∫§n r·ªìi ƒë·ª£i em x√≠uuuuuu...')
    start_time=time.time()
    result=answer(user_id,id_conversation,text)
    print("total_time: ",time.time()-start_time)
    print("*****************************************************")
    print("*****************************************************")
    print("*****************************************************")
    if submitted:
        st.info(result)
